---
layout: post
title: "Air+Touch: Interweaving Touch & In-Air Gestures"
category: publications
icon: "assets/cards/air-touch.jpg"
authors: "Xiang 'Anthony' Chen, Julia Schwarz, Chris Harrison, Jennifer Mankoff, Scott E. Hudson"
proceedings: "In Proceedings of UIST '14"
excerpt: "Anthony and I developed a class of interaction techniques that interweave touch events with in-air gestures, demonstrating
how touch and in-air gestures are highly complementary. This was a great partnership; I led the technical implementation and project logistics (development of finger tracking algorithm & API using
depth-sensing camera), while Anthony focused on making demos, design, and paper writing."
paper: "assets/air-touch/chen-airtouch-uist14.pdf"
demo_video: "https://vimeo.com/92972949"
header_image: "assets/air-touch/airtouch-banner3.jpg"
citation: "Chen, X., Schwarz, J., Harrison, C., Mankoff, J., and Hudson, S.E. Air+Touch: Interweaveing Touch & In-Air Gestures. In Proceedings of the 27th annual ACM symposium on User interface software and technology (Honolulu, Hawaii, October 5 - 9). UIST '14. ACM, New York, NY, USA, 519-525."
---
<div class="row">
    <div class="col-md-6">
        <p>
            Air+Touch is a class of new interactions that interweave touch events with in-air gestures, offering a unified input modality
            with expressiveness greater than each input modality alone. This work demonstrates how air and touch are highly complementary:
            touch is used to designate targets and segment in-air gestures, while in-air gestures add expressivity to touch events.
        </p>
        <p>
            For example, a user can draw a circle in the air and tap to trigger a context menu, do a finger 'high jump' between two touches
            to select a region of text, or drag and in-air ‘pigtail’ to copy text to the clipboard.
            To illustrate the potential of our approach, we built four applications that showcase seven exemplar Air+Touch interactions we created.
        </p>
        <p>
            Building Air+Touch was a lot of fun; I led the technical implementation and project logistics (development of finger tracking algorithm & API using
            depth-sensing camera), while Anthony focused on demo implementation, design, and paper writing. One of my most positive experiences collaborating
            with another student.
        </p>
    </div>
    <div class="col-md-6 center-block bottom-spacing" >
        <div class="top-spacing visible-sm visible-xs"></div>
        <div style="padding-top: 5px" class="visible-lg visible-md"></div>
        <iframe src="//player.vimeo.com/video/92972949" width="500" height="281" frameborder="0"
                webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>
    </div>
</div>

<div class="row">
    <div class="col-md-11">
        <h3>Timeline</h3>
        <p>January 2013 - Anthony shares his idea with me for Air+Touch interaction and I love it. I order parts and start designing prototype chasis.</p>
        <p>February 2013 - I develop finger tracking system and Air+Touch API, Anthony works on iOS demos, I work on Android demos.</p>
        <p>March 2013 - Anthony writes initial submission to UIST and develops design space.</p>
        <p>April 2013 - First submission to UIST 2013. </p>
        <p>September 2013 - Submission to CHI 2013.</p>
        <p>April 2014 - Anthony and Chris revise paper, resubmit to UIST</p>
        <p>October 2014 - Anthony presents work in Honolulu, HI.</p>
    </div>

</div>

